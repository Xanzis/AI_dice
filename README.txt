This doc should describe what all the fiels here do. Most importantly it should be used to figure out what was used to train what.

rand_v_rand_sd.ts : Generated by two random functions. If there's a clear option, ideal is that option. Else choose value of own die.
ai1_sd : Trained with rand_v_rand_sd.ts and, disappointingly, appeared to be biased towards tails. 
aisd_v_aisd_test.ts : Generated by two ai1_sd functions. Sadly, 73% of ideals are tails.
ai2_sd : trained on aisd_v_aisd_test.ts and produces far majority tails bets. New direction chosen for next set of trains.

Goal now in progress: get a network to first figure out the die, then start biasing towards playing the game well. We'll see what works best here with time.

rvr_guessown.ts : data produced with rand v rand, but ideals are just the value of the bot's die. Good balance of even / odd (ofc)
ai_guessown : trained on rvr_guessown.ts and achieves 66% success. 
aigo_v_aigo.ts : dataset on ai_guessown playing against itself.
- good news: roughly even heads-tails distribution (0.49872 tails)
aigo2: trained on aigo_v_aigo.ts
aigo2_v_aigo2.ts : dataset generated with aigo2
aigo3 : trained on aigo2_v_aigo2.ts 
- good news: performance on validation data up to 0.7841
- seems to confirm idea that eventually the bot models the behaviour of the other bot
aigo3_v_aigo3.ts : self explainatory
aigo4: trained on aigo3_v_aigo3. achieved 0.7698 accuracy (plateau possibly caused by uncertainty in dice. Figure out what theoretical max is)
more coming soon ...